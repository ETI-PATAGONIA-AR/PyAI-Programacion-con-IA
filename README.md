# PyAI - El asistente t√©cnico de programaci√≥n que emplea IA -

## Para que sirve esta herramienta?

PyAI es una herramienta de asistencia basada en Inteligencia Artificial desarrollada en Python, pensada desde el inicio como una aplicaci√≥n de escritorio real y usable, no como un simple chatbot de prueba ni una demo de modelos de lenguaje. El proyecto nace de la necesidad de contar con un asistente que pueda acompa√±ar procesos t√©cnicos, educativos y creativos de manera flexible, manteniendo contexto y adapt√°ndose a la persona que lo utiliza.

Pueden ver el video con los primeros pasos ( https://youtu.be/04bbXQ0UP4U )

[![M√≠ralo en YouTube](https://i.ytimg.com/an_webp/04bbXQ0UP4U/mqdefault_6s.webp?du=3000&sqp=CKDTr8wG&rs=AOn4CLDT5_CojV5bQdD6dyjhIHkPGYlKHw)](https://youtu.be/04bbXQ0UP4U)


La idea central detr√°s de PyAI es que la inteligencia artificial se adapte al usuario y a su forma de trabajar, aprender o razonar, y no que el usuario tenga que amoldarse a las limitaciones de la IA.



Este repositorio corresponde exclusivamente a la versi√≥n On-Line de PyAI, que funciona mediante el consumo de modelos de lenguaje ejecutados en la nube a trav√©s de la plataforma Groq; La versi√≥n Off-Line, me reservo los derechos a compartirlo solo con los que son seguidores activos y que no solo me acompa√±an alent√°ndome en cada trabajo, en cada proyecto, sino que tambi√©n me inspiran con sus mensajes de aliento, e incluso ideas de mejoras funcionales.

La versi√≥n On-Line de PyAI est√° orientada principalmente a la asistencia t√©cnica, el desarrollo de software, el an√°lisis de c√≥digo y la resoluci√≥n de problemas complejos. Aprovecha la infraestructura de Groq para obtener inferencias de muy baja latencia y alta calidad, sin necesidad de ejecutar modelos pesados de forma local ni contar con hardware especializado.

PyAI fue dise√±ado con una arquitectura modular, lo que permite que distintas versiones del proyecto compartan una misma base conceptual y estructural, pero se adapten a distintos entornos y p√∫blicos. Actualmente, el ecosistema PyAI contempla tres l√≠neas / versiones principales de desarrollo.



https://github.com/user-attachments/assets/d937c7b1-c7b4-431d-8ca4-1f618e9e21ec



---

## Las distintas Versiones de una misma base:

- La primera es esta versi√≥n On-Line (PyAI_v1), enfocada en usuarios t√©cnicos y desarrolladores, que prioriza potencia, velocidad de respuesta y precisi√≥n. Es ideal para programaci√≥n, scripting, an√°lisis t√©cnico y asistencia contextual en proyectos reales de programaci√≥n en Python, como asi tambi√©n, en C++/Arduino y estoy en fase beta probando otros lenguajes mas.

- La segunda es una versi√≥n Off-Line (PyAI_v2), desarrollada para funcionar completamente sin conexi√≥n a internet. Esta variante utiliza modelos descargables que se ejecutan de manera local y est√° pensada para entornos donde no hay conectividad, o donde se requiere control total sobre los datos y el modelo. Esta versi√≥n se publicar√° como un proyecto independiente, y como mencione anteriormente, estar√° semi-restringida.

- La tercera es una versi√≥n educativa (ProfeAI), orientada a ni√±os y adolescentes de nivel primario y secundario. En esta variante se incorporaron TTS (herramientas de Text To Speech - Generaci√≥n de de Texto a Voz) y un fuerte trabajo pedag√≥gico, con el objetivo de que la IA pueda actuar como un profesor particular de matem√°ticas. En esta versi√≥n, la inteligencia artificial se adapta al alumno, a su nivel y a su ritmo de aprendizaje, explicando los conceptos de distintas maneras hasta lograr comprensi√≥n, evitando un enfoque r√≠gido o acad√©mico tradicional.

---

## PyAI_v1:

En la versi√≥n On-Line, PyAI utiliza modelos de lenguaje de gran escala provistos por Groq. El modelo principal empleado es LLaMA 3 de 70 mil millones de par√°metros, en variantes como llama3-70b-8192 seg√∫n disponibilidad. Groq permite trabajar con modelos de alto nivel de razonamiento, excelente desempe√±o en tareas t√©cnicas y una latencia muy baja, lo que mejora notablemente la experiencia de uso.
Para utilizar PyAI en modo On-Line es obligatorio contar con una API Key personal de Groq. El archivo api_key.txt incluido en el proyecto no contiene ninguna clave v√°lida por defecto. Cada usuario debe generar su propia clave desde su cuenta de Groq y colocarla manualmente en ese archivo. Es importante no subir nunca la API Key a un repositorio p√∫blico.
PyAI est√° desarrollado en Python y requiere Python versi√≥n 3.10 o superior. Las dependencias necesarias se encuentran definidas dentro del proyecto y est√°n orientadas a mantener una estructura clara, modular y f√°cil de extender.
Actualmente, la versi√≥n On-Line de PyAI permite mantener conversaciones con contexto, asistir en tareas t√©cnicas complejas, trabajar sobre proyectos reales y servir como base para futuras extensiones. Este repositorio representa una parte fundamental del ecosistema PyAI, pero no agota el alcance total del proyecto.

PyAI es un proyecto en evoluci√≥n constante. Todas sus variantes comparten una misma filosof√≠a: utilizar la inteligencia artificial como una herramienta que acompa√±a, explica y se adapta, en lugar de imponer un modelo r√≠gido de interacci√≥n.

---

** Recuerden que deben generar sus propias api key de Groq y pegarla en un archivo TXT llamado "api_key.txt" y alojarlo dentro de la carpeta "PyAI_onLINE\config" **

## üîë Configuraci√≥n de Groq API Key

Para que PyAI funcione correctamente, necesitas una cuenta en Groq y una API Key. Sigue estos pasos:

- Crear una cuenta en Groq ( Ingresa a https://groq.com/ )

- Haz clic en Sign Up / Registrarse y completa tus datos.

- Generar tu API Key; Para ello inicia sesi√≥n en tu cuenta Groq / --Ve a Dashboard ‚Üí API Keys.

- Haz clic en Create API Key / Generar clave.

- Copia la clave generada.

- Guardar la API Key localmente

- Dentro del proyecto, ve a la carpeta config/.

- Crea un archivo llamado api_key.txt si no existe y pega tu API Key dentro y guarda el archivo.

- El archivo deber√≠a contener solo tu API Key y nada m√°s.

- Para probar la configuraci√≥n, ejecuta el proyecto (run_PyAI_v1.bat)... Si todo est√° correcto, la conexi√≥n con Groq funcionar√° autom√°ticamente.

‚ö†Ô∏è Importante: No compartas tu API Key con nadie y no la subas al repositorio p√∫blico.

---

** Paso los CMD para instalar las dependencias: **

 1Ô∏è‚É£ Actualizar pip a la √∫ltima versi√≥n

python -m pip install --upgrade pip

---

 2Ô∏è‚É£ Instalar dependencias globales del proyecto

pip install PyQt5==5.15.11

pip install requests==2.32.5

pip install Pygments==2.19.2

pip install pyttsx3

---

## NOTA (12/02/2026) "Aclaraci√≥n importante sobre cambios en modelos y servicios externos"***

Ante el cambios de los ecosistema de modelos gratuitos sin previo aviso por parte de los proveedores:

- relajaron filtros

- priorizan chat

- rompen RAG

- empujan pago

Durante el desarrollo de este proyecto, varias de las plataformas y modelos de Inteligencia Artificial que ofrec√≠an acceso gratuito o semi-gratuito cambiaron sus reglas de uso, disponibilidad o pol√≠ticas de acceso. Esto impact√≥ directamente en muchos proyectos que, como PyAI, funcionaban correctamente en su momento y luego dejaron de hacerlo sin que hubiera cambios en el c√≥digo.

***En particular, se vieron afectados los siguientes casos.***

En el ecosistema Groq, varios modelos abiertos que antes pod√≠an utilizarse de manera simple dejaron de estar disponibles o cambiaron sus condiciones. Los modelos LLaMA 2 en sus variantes de 7B y 13B fueron discontinuados por Meta y, en consecuencia, Groq dej√≥ de ofrecerlos. Proyectos que depend√≠an de estos modelos ya no pueden utilizarlos.

El modelo Mixtral 8x7B Instruct sigue existiendo en Groq, pero ya no funciona como antes. Actualmente requiere una API Key obligatoria, tiene l√≠mites de uso m√°s estrictos y ya no puede considerarse un recurso libre o plug and play. Cualquier proyecto que antes funcionara sin clave o con configuraciones m√≠nimas puede fallar debido a estos cambios.

En el caso de los modelos Gemma de Google, el acceso tambi√©n se volvi√≥ m√°s restrictivo. No siempre est√°n disponibles y su comportamiento no es ideal para ciertos usos t√©cnicos, especialmente cuando se requiere precisi√≥n estricta o recuperaci√≥n de informaci√≥n basada en contexto, ya que tienden a generar respuestas m√°s interpretativas.

En paralelo, la API de inferencia gratuita de HuggingFace sufri√≥ una degradaci√≥n importante. El nivel gratuito cl√°sico se volvi√≥ extremadamente limitado o directamente inutilizable en muchos escenarios reales. Es com√∫n experimentar tiempos de espera muy largos, modelos que permanecen inactivos, respuestas vac√≠as o directamente fallos de ejecuci√≥n. Modelos que antes rend√≠an aceptablemente en ese entorno, como Mistral 7B Instruct o LLaMA 2, dejaron de ser una opci√≥n viable en el free tier.

La conclusi√≥n general es que ya no existe un acceso verdaderamente gratuito, estable y plug and play a modelos grandes a trav√©s de estas plataformas, como ocurr√≠a meses atr√°s. PyAI no dej√≥ de funcionar por errores propios, sino que se vio afectado por cambios externos en los servicios de inferencia.

Por este motivo, el proyecto evolucion√≥ y se dividi√≥ en distintas variantes. Esta versi√≥n On-Line utiliza Groq con API Key obligatoria y modelos actualmente soportados. Otras versiones del proyecto apuntan a resolver estas limitaciones mediante ejecuci√≥n local y funcionamiento completamente offline.

Si al clonar el repositorio experiment√°s errores relacionados con modelos, disponibilidad o acceso, revis√° que est√©s utilizando un modelo actualmente soportado y que hayas configurado correctamente tu propia API Key.

## Modelos que probamos y ya no funcionan como antes / se cayeron

‚ùå ***Groq ‚Äì llama2-70b-4096*** ‚úîÔ∏è Funcionaba al inicio - ‚ùå Dej√≥ de estar disponible - Motivo: LLaMA 2 fue discontinuado ... Estado actual: NO EXISTE en Groq

‚ùå ***Groq ‚Äì llama2-7b / llama2-13b*** ‚úîÔ∏è Usados en pruebas iniciales - ‚ùå Retirados  

‚ö†Ô∏è ***Groq ‚Äì gemma-7b-it*** ‚úîÔ∏è Probado - ‚ùå Muy verborr√°gico - ‚ùå P√©simo siguiendo modo scripting - ‚ùå Alucina incluso con contexto cargado ... Estado: DESCARTADO

‚ùå ***HuggingFace ‚Äì mistral-7b-instruct (Inference API free)*** ‚úîÔ∏è Probado - ‚ùå Timeouts - ‚ùå Se ‚Äúduerme‚Äù - ‚ùå Respuestas incompletas ... Estado: INUTILIZABLE en free

‚ùå ***HuggingFace ‚Äì llama-2- (Inference API)*** ‚úîÔ∏è Probado - ‚ùå Retirado / bloqueado ... Estado: MUERTO

---

## Posibles soluciones:

Bien, veamos un peque√±o paso a paso, de como editar nuestro programa y probar otros modelos de Groq sin romper PyAI...

***PASO 1***

Entender qu√© parte del archivo define el modelo; O sea, en  groq_client.py NO hay ning√∫n modelo hardcodeado. 
El modelo se toma desde este punto:

```python
payload = {
    "model": self.settings["model"],
    "temperature": self.settings["temperature"],
    "max_tokens": self.settings["max_tokens"],
    "messages": messages
}
```

Eso significa que el modelo NO se cambia ac√°, sino en:

```arduino
config/settings.json
```

***PASO 2 - Ubicar el archivo correcto a editar***

Abr√≠ este archivo del proyecto:

```arduino
config/settings.json
```

Un ejemplo t√≠pico puede verse as√≠:

```python
{
    "model": "mixtral-8x7b-32768",
    "temperature": 0.7,
    "max_tokens": 1024
}
```

***PASO 3 - Cambiar el modelo (ejemplos reales)***

Para probar otro modelo de Groq, solo cambi√°s el valor de "model". Ejemplos v√°lidos (dependen de disponibilidad en tu cuenta Groq):

- Mixtral 8x7B Instruct: "model": "mixtral-8x7b-32768"

- LLaMA 3 8B Instruct: "model": "llama3-8b-8192"

- LLaMA 3 70B Instruct (si tu cuenta lo permite): "model": "llama3-70b-8192"

- Gemma 7B: "model": "gemma-7b-it"

y el resto queda exactamente igual; No hace falta tocar nada m√°s.

***PASO 4 - Ajustar tokens seg√∫n el modelo (opcional pero recomendado)***

Modelos m√°s grandes toleran m√°s contexto, pero tambi√©n consumen m√°s. Ejemplo conservador y estable:

```python
{
    "model": "llama3-8b-8192",
    "temperature": 0.6,
    "max_tokens": 800
}
```

Si pon√©s max_tokens demasiado alto y el modelo no lo soporta ‚Üí error de API.

***PASO 5 - Guardar y ejecutar PyAI normalmente***

No hay que reiniciar nada raro; Simplemente:

```arduino
python main.py
```

PyAI va a usar el nuevo modelo autom√°ticamente.

***PASO 6 - C√≥mo saber si el modelo no est√° disponible***

Si el modelo no existe o no est√° habilitado, vas a ver errores como:

```arduino
HTTP 400 / 404

"model not found"

"model not available for this account"
```

En ese caso, Volv√© a 

```arduino
settings.json
```

y prob√° otro modelo

***PASO 7 - Qu√© NO hacer (errores comunes)***

- NO pongas el modelo hardcodeado en groq_client.py
- NO edites la URL
- NO cambies headers
- NO dupliques l√≥gica

---

Lamento en lo mas profundo lo que esta sucediendo, es por ello que voy agilizar las cosas para compartir el modelo OffLINE y no depender de estas cosas insolitas que hacen los proveedores.

Los saludo atte
